# Simulaci贸n y An谩lisis de C贸digos de Bloque (14,10) en Canal AWGN

Este repositorio contiene el desarrollo de un trabajo pr谩ctico para la materia **Teor铆a de la Informaci贸n y Codificaci贸n**, en el que se implementan y eval煤an c贸digos de bloque binarios sobre canales ruidosos (AWGN), utilizando modulaci贸n BPSK. Se simulan tanto escenarios con **correcci贸n de errores** como con **detecci贸n de errores**, y adem谩s se realiza una compresi贸n de fuente utilizando **codificaci贸n de Huffman** sobre una imagen binaria.

---

##  Objetivos

- Implementar un sistema transmisor-receptor con un c贸digo (14,10) de bloques.
- Evaluar el desempe帽o del sistema bajo diferentes condiciones de ruido (Eb/N0).
- Comparar resultados simulados con resultados te贸ricos.
- Estimar **ganancia de codificaci贸n** (real y asint贸tica).
- Implementar **detecci贸n de errores** sin retransmisi贸n.
- Aplicar **compresi贸n de fuente** sobre una imagen binaria utilizando Huffman para fuente extendida de orden 2 y 3.

---


## 锔 C贸mo ejecutar

1. Asegurarse de tener las dependencias instaladas:
```bash
pip install numpy matplotlib pillow scipy
```

2. Ejecutar simulaci贸n para corrector:
### En la carpeta /canal
```python
modo = ModoSimulacion.CORRECTOR
```
```bash
python main.py
```
3. Ejecutar simulaci贸n para detector:
### En la carpeta /canal
```python
modo = ModoSimulacion.DETECTOR
```
```bash
python main.py
```

4. Ejecutar compresi贸n de fuente:
### En la carpeta /fuente
```bash
python main.py
```

##  Resultados

- **Curvas BER y WER** simuladas vs. teor铆a sin codificaci贸n.
- **Ganancia real** del c贸digo frente a **ganancia asint贸tica**.
- Para el modo **detector**, se aclara que no se considera retransmisi贸n: las palabras con errores detectados son descartadas sin reenv铆o.
- **Compresi贸n Huffman** con orden 2 y 3, mostrando el largo promedio por s铆mbolo y la tasa de compresi贸n obtenida.

---

##  Notas importantes

- El c贸digo detector filtra las palabras err贸neas, lo que puede **subestimar la BER** ya que solo se computa sobre palabras "aceptadas".
- En todos los experimentos se trabaja con bloques aleatorios de 1.000.000 de palabras por punto Eb/N0 para garantizar consistencia estad铆stica.
